This is bison.info, produced by makeinfo version 4.2 from
/netrel/src/bison-20030307-1/doc/bison.texinfo.



   This manual is for GNU Bison (version 1.875b, 2 March 2003), the GNU
parser generator.

   Copyright (C) 1988, 1989, 1990, 1991, 1992, 1993, 1995, 1998, 2003,
1999, 2000, 2001, 2002, 2003 Free Software Foundation, Inc.

     Permission is granted to copy, distribute and/or modify this
     document under the terms of the GNU Free Documentation License,
     Version 1.1 or any later version published by the Free Software
     Foundation; with no Invariant Sections, with the Front-Cover texts
     being "A GNU Manual," and with the Back-Cover Texts as in (a)
     below.  A copy of the license is included in the section entitled
     "GNU Free Documentation License."

     (a) The FSF's Back-Cover Text is: "You have freedom to copy and
     modify this GNU Manual, like GNU software.  Copies published by
     the Free Software Foundation raise funds for GNU development."
   
INFO-DIR-SECTION GNU programming tools
START-INFO-DIR-ENTRY
* bison: (bison).       GNU parser generator (Yacc replacement).
END-INFO-DIR-ENTRY


File: bison.info,  Node: Mystery Conflicts,  Next: Generalized LR Parsing,  Prev: Reduce/Reduce,  Up: Algorithm

Mysterious Reduce/Reduce Conflicts
==================================

   Sometimes reduce/reduce conflicts can occur that don't look
warranted.  Here is an example:

     %token ID
     
     %%
     def:    param_spec return_spec ','
             ;
     param_spec:
                  type
             |    name_list ':' type
             ;
     return_spec:
                  type
             |    name ':' type
             ;
     type:        ID
             ;
     name:        ID
             ;
     name_list:
                  name
             |    name ',' name_list
             ;

   It would seem that this grammar can be parsed with only a single
token of look-ahead: when a `param_spec' is being read, an `ID' is a
`name' if a comma or colon follows, or a `type' if another `ID'
follows.  In other words, this grammar is LR(1).

   However, Bison, like most parser generators, cannot actually handle
all LR(1) grammars.  In this grammar, two contexts, that after an `ID'
at the beginning of a `param_spec' and likewise at the beginning of a
`return_spec', are similar enough that Bison assumes they are the same.
They appear similar because the same set of rules would be active--the
rule for reducing to a `name' and that for reducing to a `type'.  Bison
is unable to determine at that stage of processing that the rules would
require different look-ahead tokens in the two contexts, so it makes a
single parser state for them both.  Combining the two contexts causes a
conflict later.  In parser terminology, this occurrence means that the
grammar is not LALR(1).

   In general, it is better to fix deficiencies than to document them.
But this particular deficiency is intrinsically hard to fix; parser
generators that can handle LR(1) grammars are hard to write and tend to
produce parsers that are very large.  In practice, Bison is more useful
as it is now.

   When the problem arises, you can often fix it by identifying the two
parser states that are being confused, and adding something to make them
look distinct.  In the above example, adding one rule to `return_spec'
as follows makes the problem go away:

     %token BOGUS
     ...
     %%
     ...
     return_spec:
                  type
             |    name ':' type
             /* This rule is never used.  */
             |    ID BOGUS
             ;

   This corrects the problem because it introduces the possibility of an
additional active rule in the context after the `ID' at the beginning of
`return_spec'.  This rule is not active in the corresponding context in
a `param_spec', so the two contexts receive distinct parser states.  As
long as the token `BOGUS' is never generated by `yylex', the added rule
cannot alter the way actual input is parsed.

   In this particular example, there is another way to solve the
problem: rewrite the rule for `return_spec' to use `ID' directly
instead of via `name'.  This also causes the two confusing contexts to
have different sets of active rules, because the one for `return_spec'
activates the altered rule for `return_spec' rather than the one for
`name'.

     param_spec:
                  type
             |    name_list ':' type
             ;
     return_spec:
                  type
             |    ID ':' type
             ;


File: bison.info,  Node: Generalized LR Parsing,  Next: Stack Overflow,  Prev: Mystery Conflicts,  Up: Algorithm

Generalized LR (GLR) Parsing
============================

   Bison produces _deterministic_ parsers that choose uniquely when to
reduce and which reduction to apply based on a summary of the preceding
input and on one extra token of lookahead.  As a result, normal Bison
handles a proper subset of the family of context-free languages.
Ambiguous grammars, since they have strings with more than one possible
sequence of reductions cannot have deterministic parsers in this sense.
The same is true of languages that require more than one symbol of
lookahead, since the parser lacks the information necessary to make a
decision at the point it must be made in a shift-reduce parser.
Finally, as previously mentioned (*note Mystery Conflicts::), there are
languages where Bison's particular choice of how to summarize the input
seen so far loses necessary information.

   When you use the `%glr-parser' declaration in your grammar file,
Bison generates a parser that uses a different algorithm, called
Generalized LR (or GLR).  A Bison GLR parser uses the same basic
algorithm for parsing as an ordinary Bison parser, but behaves
differently in cases where there is a shift-reduce conflict that has not
been resolved by precedence rules (*note Precedence::) or a
reduce-reduce conflict.  When a GLR parser encounters such a situation,
it effectively _splits_ into a several parsers, one for each possible
shift or reduction.  These parsers then proceed as usual, consuming
tokens in lock-step.  Some of the stacks may encounter other conflicts
and split further, with the result that instead of a sequence of states,
a Bison GLR parsing stack is what is in effect a tree of states.

   In effect, each stack represents a guess as to what the proper parse
is.  Additional input may indicate that a guess was wrong, in which case
the appropriate stack silently disappears.  Otherwise, the semantics
actions generated in each stack are saved, rather than being executed
immediately.  When a stack disappears, its saved semantic actions never
get executed.  When a reduction causes two stacks to become equivalent,
their sets of semantic actions are both saved with the state that
results from the reduction.  We say that two stacks are equivalent when
they both represent the same sequence of states, and each pair of
corresponding states represents a grammar symbol that produces the same
segment of the input token stream.

   Whenever the parser makes a transition from having multiple states
to having one, it reverts to the normal LALR(1) parsing algorithm,
after resolving and executing the saved-up actions.  At this
transition, some of the states on the stack will have semantic values
that are sets (actually multisets) of possible actions.  The parser
tries to pick one of the actions by first finding one whose rule has
the highest dynamic precedence, as set by the `%dprec' declaration.
Otherwise, if the alternative actions are not ordered by precedence,
but there the same merging function is declared for both rules by the
`%merge' declaration, Bison resolves and evaluates both and then calls
the merge function on the result.  Otherwise, it reports an ambiguity.

   It is possible to use a data structure for the GLR parsing tree that
permits the processing of any LALR(1) grammar in linear time (in the
size of the input), any unambiguous (not necessarily LALR(1)) grammar in
quadratic worst-case time, and any general (possibly ambiguous)
context-free grammar in cubic worst-case time.  However, Bison currently
uses a simpler data structure that requires time proportional to the
length of the input times the maximum number of stacks required for any
prefix of the input.  Thus, really ambiguous or non-deterministic
grammars can require exponential time and space to process.  Such badly
behaving examples, however, are not generally of practical interest.
Usually, non-determinism in a grammar is local--the parser is "in
doubt" only for a few tokens at a time.  Therefore, the current data
structure should generally be adequate.  On LALR(1) portions of a
grammar, in particular, it is only slightly slower than with the default
Bison parser.

   For a more detailed exposition of GLR parsers, please see: Elizabeth
Scott, Adrian Johnstone and Shamsa Sadaf Hussain, Tomita-Style
Generalised LR Parsers, Royal Holloway, University of London,
Department of Computer Science, TR-00-12,
`http://www.cs.rhul.ac.uk/research/languages/publications/tomita_style_1.ps',
(2000-12-24).


File: bison.info,  Node: Stack Overflow,  Prev: Generalized LR Parsing,  Up: Algorithm

Stack Overflow, and How to Avoid It
===================================

   The Bison parser stack can overflow if too many tokens are shifted
and not reduced.  When this happens, the parser function `yyparse'
returns a nonzero value, pausing only to call `yyerror' to report the
overflow.

   Because Bison parsers have growing stacks, hitting the upper limit
usually results from using a right recursion instead of a left
recursion, *Note Recursive Rules: Recursion.

   By defining the macro `YYMAXDEPTH', you can control how deep the
parser stack can become before a stack overflow occurs.  Define the
macro with a value that is an integer.  This value is the maximum number
of tokens that can be shifted (and not reduced) before overflow.  It
must be a constant expression whose value is known at compile time.

   The stack space allowed is not necessarily allocated.  If you
specify a large value for `YYMAXDEPTH', the parser actually allocates a
small stack at first, and then makes it bigger by stages as needed.
This increasing allocation happens automatically and silently.
Therefore, you do not need to make `YYMAXDEPTH' painfully small merely
to save space for ordinary inputs that do not need much stack.

   The default value of `YYMAXDEPTH', if you do not define it, is 10000.

   You can control how much stack is allocated initially by defining the
macro `YYINITDEPTH'.  This value too must be a compile-time constant
integer.  The default is 200.

   Because of semantical differences between C and C++, the LALR(1)
parsers in C produced by Bison by compiled as C++ cannot grow.  In this
precise case (compiling a C parser as C++) you are suggested to grow
`YYINITDEPTH'.  In the near future, a C++ output output will be
provided which addresses this issue.


File: bison.info,  Node: Error Recovery,  Next: Context Dependency,  Prev: Algorithm,  Up: Top

Error Recovery
**************

   It is not usually acceptable to have a program terminate on a syntax
error.  For example, a compiler should recover sufficiently to parse the
rest of the input file and check it for errors; a calculator should
accept another expression.

   In a simple interactive command parser where each input is one line,
it may be sufficient to allow `yyparse' to return 1 on error and have
the caller ignore the rest of the input line when that happens (and
then call `yyparse' again).  But this is inadequate for a compiler,
because it forgets all the syntactic context leading up to the error.
A syntax error deep within a function in the compiler input should not
cause the compiler to treat the following line like the beginning of a
source file.

   You can define how to recover from a syntax error by writing rules to
recognize the special token `error'.  This is a terminal symbol that is
always defined (you need not declare it) and reserved for error
handling.  The Bison parser generates an `error' token whenever a
syntax error happens; if you have provided a rule to recognize this
token in the current context, the parse can continue.

   For example:

     stmnts:  /* empty string */
             | stmnts '\n'
             | stmnts exp '\n'
             | stmnts error '\n'

   The fourth rule in this example says that an error followed by a
newline makes a valid addition to any `stmnts'.

   What happens if a syntax error occurs in the middle of an `exp'?  The
error recovery rule, interpreted strictly, applies to the precise
sequence of a `stmnts', an `error' and a newline.  If an error occurs in
the middle of an `exp', there will probably be some additional tokens
and subexpressions on the stack after the last `stmnts', and there will
be tokens to read before the next newline.  So the rule is not
applicable in the ordinary way.

   But Bison can force the situation to fit the rule, by discarding
part of the semantic context and part of the input.  First it discards
states and objects from the stack until it gets back to a state in
which the `error' token is acceptable.  (This means that the
subexpressions already parsed are discarded, back to the last complete
`stmnts'.)  At this point the `error' token can be shifted.  Then, if
the old look-ahead token is not acceptable to be shifted next, the
parser reads tokens and discards them until it finds a token which is
acceptable.  In this example, Bison reads and discards input until the
next newline so that the fourth rule can apply.  Note that discarded
symbols are possible sources of memory leaks, see *Note Freeing
Discarded Symbols: Destructor Decl, for a means to reclaim this memory.

   The choice of error rules in the grammar is a choice of strategies
for error recovery.  A simple and useful strategy is simply to skip the
rest of the current input line or current statement if an error is
detected:

     stmnt: error ';'  /* On error, skip until ';' is read.  */

   It is also useful to recover to the matching close-delimiter of an
opening-delimiter that has already been parsed.  Otherwise the
close-delimiter will probably appear to be unmatched, and generate
another, spurious error message:

     primary:  '(' expr ')'
             | '(' error ')'
             ...
             ;

   Error recovery strategies are necessarily guesses.  When they guess
wrong, one syntax error often leads to another.  In the above example,
the error recovery rule guesses that an error is due to bad input
within one `stmnt'.  Suppose that instead a spurious semicolon is
inserted in the middle of a valid `stmnt'.  After the error recovery
rule recovers from the first error, another syntax error will be found
straightaway, since the text following the spurious semicolon is also
an invalid `stmnt'.

   To prevent an outpouring of error messages, the parser will output
no error message for another syntax error that happens shortly after
the first; only after three consecutive input tokens have been
successfully shifted will error messages resume.

   Note that rules which accept the `error' token may have actions, just
as any other rules can.

   You can make error messages resume immediately by using the macro
`yyerrok' in an action.  If you do this in the error rule's action, no
error messages will be suppressed.  This macro requires no arguments;
`yyerrok;' is a valid C statement.

   The previous look-ahead token is reanalyzed immediately after an
error.  If this is unacceptable, then the macro `yyclearin' may be used
to clear this token.  Write the statement `yyclearin;' in the error
rule's action.

   For example, suppose that on a syntax error, an error handling
routine is called that advances the input stream to some point where
parsing should once again commence.  The next symbol returned by the
lexical scanner is probably correct.  The previous look-ahead token
ought to be discarded with `yyclearin;'.

   The macro `YYRECOVERING' stands for an expression that has the value
1 when the parser is recovering from a syntax error, and 0 the rest of
the time.  A value of 1 indicates that error messages are currently
suppressed for new syntax errors.


File: bison.info,  Node: Context Dependency,  Next: Debugging,  Prev: Error Recovery,  Up: Top

Handling Context Dependencies
*****************************

   The Bison paradigm is to parse tokens first, then group them into
larger syntactic units.  In many languages, the meaning of a token is
affected by its context.  Although this violates the Bison paradigm,
certain techniques (known as "kludges") may enable you to write Bison
parsers for such languages.

* Menu:

* Semantic Tokens::   Token parsing can depend on the semantic context.
* Lexical Tie-ins::   Token parsing can depend on the syntactic context.
* Tie-in Recovery::   Lexical tie-ins have implications for how
                        error recovery rules must be written.

   (Actually, "kludge" means any technique that gets its job done but is
neither clean nor robust.)


File: bison.info,  Node: Semantic Tokens,  Next: Lexical Tie-ins,  Up: Context Dependency

Semantic Info in Token Types
============================

   The C language has a context dependency: the way an identifier is
used depends on what its current meaning is.  For example, consider
this:

     foo (x);

   This looks like a function call statement, but if `foo' is a typedef
name, then this is actually a declaration of `x'.  How can a Bison
parser for C decide how to parse this input?

   The method used in GNU C is to have two different token types,
`IDENTIFIER' and `TYPENAME'.  When `yylex' finds an identifier, it
looks up the current declaration of the identifier in order to decide
which token type to return: `TYPENAME' if the identifier is declared as
a typedef, `IDENTIFIER' otherwise.

   The grammar rules can then express the context dependency by the
choice of token type to recognize.  `IDENTIFIER' is accepted as an
expression, but `TYPENAME' is not.  `TYPENAME' can start a declaration,
but `IDENTIFIER' cannot.  In contexts where the meaning of the
identifier is _not_ significant, such as in declarations that can
shadow a typedef name, either `TYPENAME' or `IDENTIFIER' is
accepted--there is one rule for each of the two token types.

   This technique is simple to use if the decision of which kinds of
identifiers to allow is made at a place close to where the identifier is
parsed.  But in C this is not always so: C allows a declaration to
redeclare a typedef name provided an explicit type has been specified
earlier:

     typedef int foo, bar, lose;
     static foo (bar);        /* redeclare `bar' as static variable */
     static int foo (lose);   /* redeclare `foo' as function */

   Unfortunately, the name being declared is separated from the
declaration construct itself by a complicated syntactic structure--the
"declarator".

   As a result, part of the Bison parser for C needs to be duplicated,
with all the nonterminal names changed: once for parsing a declaration
in which a typedef name can be redefined, and once for parsing a
declaration in which that can't be done.  Here is a part of the
duplication, with actions omitted for brevity:

     initdcl:
               declarator maybeasm '='
               init
             | declarator maybeasm
             ;
     
     notype_initdcl:
               notype_declarator maybeasm '='
               init
             | notype_declarator maybeasm
             ;

Here `initdcl' can redeclare a typedef name, but `notype_initdcl'
cannot.  The distinction between `declarator' and `notype_declarator'
is the same sort of thing.

   There is some similarity between this technique and a lexical tie-in
(described next), in that information which alters the lexical analysis
is changed during parsing by other parts of the program.  The
difference is here the information is global, and is used for other
purposes in the program.  A true lexical tie-in has a special-purpose
flag controlled by the syntactic context.


File: bison.info,  Node: Lexical Tie-ins,  Next: Tie-in Recovery,  Prev: Semantic Tokens,  Up: Context Dependency

Lexical Tie-ins
===============

   One way to handle context-dependency is the "lexical tie-in": a flag
which is set by Bison actions, whose purpose is to alter the way tokens
are parsed.

   For example, suppose we have a language vaguely like C, but with a
special construct `hex (HEX-EXPR)'.  After the keyword `hex' comes an
expression in parentheses in which all integers are hexadecimal.  In
particular, the token `a1b' must be treated as an integer rather than
as an identifier if it appears in that context.  Here is how you can do
it:

     %{
       int hexflag;
       int yylex (void);
       void yyerror (char const *);
     %}
     %%
     ...
     expr:   IDENTIFIER
             | constant
             | HEX '('
                     { hexflag = 1; }
               expr ')'
                     { hexflag = 0;
                        $$ = $4; }
             | expr '+' expr
                     { $$ = make_sum ($1, $3); }
             ...
             ;
     
     constant:
               INTEGER
             | STRING
             ;

Here we assume that `yylex' looks at the value of `hexflag'; when it is
nonzero, all integers are parsed in hexadecimal, and tokens starting
with letters are parsed as integers if possible.

   The declaration of `hexflag' shown in the prologue of the parser file
is needed to make it accessible to the actions (*note The Prologue:
Prologue.).  You must also write the code in `yylex' to obey the flag.


File: bison.info,  Node: Tie-in Recovery,  Prev: Lexical Tie-ins,  Up: Context Dependency

Lexical Tie-ins and Error Recovery
==================================

   Lexical tie-ins make strict demands on any error recovery rules you
have.  *Note Error Recovery::.

   The reason for this is that the purpose of an error recovery rule is
to abort the parsing of one construct and resume in some larger
construct.  For example, in C-like languages, a typical error recovery
rule is to skip tokens until the next semicolon, and then start a new
statement, like this:

     stmt:   expr ';'
             | IF '(' expr ')' stmt { ... }
             ...
             error ';'
                     { hexflag = 0; }
             ;

   If there is a syntax error in the middle of a `hex (EXPR)'
construct, this error rule will apply, and then the action for the
completed `hex (EXPR)' will never run.  So `hexflag' would remain set
for the entire rest of the input, or until the next `hex' keyword,
causing identifiers to be misinterpreted as integers.

   To avoid this problem the error recovery rule itself clears
`hexflag'.

   There may also be an error recovery rule that works within
expressions.  For example, there could be a rule which applies within
parentheses and skips to the close-parenthesis:

     expr:   ...
             | '(' expr ')'
                     { $$ = $2; }
             | '(' error ')'
             ...

   If this rule acts within the `hex' construct, it is not going to
abort that construct (since it applies to an inner level of parentheses
within the construct).  Therefore, it should not clear the flag: the
rest of the `hex' construct should be parsed with the flag still in
effect.

   What if there is an error recovery rule which might abort out of the
`hex' construct or might not, depending on circumstances?  There is no
way you can write the action to determine whether a `hex' construct is
being aborted or not.  So if you are using a lexical tie-in, you had
better make sure your error recovery rules are not of this kind.  Each
rule must be such that you can be sure that it always will, or always
won't, have to clear the flag.


File: bison.info,  Node: Debugging,  Next: Invocation,  Prev: Context Dependency,  Up: Top

Debugging Your Parser
*********************

   Developing a parser can be a challenge, especially if you don't
understand the algorithm (*note The Bison Parser Algorithm:
Algorithm.).  Even so, sometimes a detailed description of the automaton
can help (*note Understanding Your Parser: Understanding.), or tracing
the execution of the parser can give some insight on why it behaves
improperly (*note Tracing Your Parser: Tracing.).

* Menu:

* Understanding::     Understanding the structure of your parser.
* Tracing::           Tracing the execution of your parser.


File: bison.info,  Node: Understanding,  Next: Tracing,  Up: Debugging

Understanding Your Parser
=========================

   As documented elsewhere (*note The Bison Parser Algorithm:
Algorithm.)  Bison parsers are "shift/reduce automata".  In some cases
(much more frequent than one would hope), looking at this automaton is
required to tune or simply fix a parser.  Bison provides two different
representation of it, either textually or graphically (as a VCG file).

   The textual file is generated when the options `--report' or
`--verbose' are specified, see *Note Invoking Bison: Invocation.  Its
name is made by removing `.tab.c' or `.c' from the parser output file
name, and adding `.output' instead.  Therefore, if the input file is
`foo.y', then the parser file is called `foo.tab.c' by default.  As a
consequence, the verbose output file is called `foo.output'.

   The following grammar file, `calc.y', will be used in the sequel:

     %token NUM STR
     %left '+' '-'
     %left '*'
     %%
     exp: exp '+' exp
        | exp '-' exp
        | exp '*' exp
        | exp '/' exp
        | NUM
        ;
     useless: STR;
     %%

   `bison' reports:

     calc.y: warning: 1 useless nonterminal and 1 useless rule
     calc.y:11.1-7: warning: useless nonterminal: useless
     calc.y:11.10-12: warning: useless rule: useless: STR
     calc.y: conflicts: 7 shift/reduce

   When given `--report=state', in addition to `calc.tab.c', it creates
a file `calc.output' with contents detailed below.  The order of the
output and the exact presentation might vary, but the interpretation is
the same.

   The first section includes details on conflicts that were solved
thanks to precedence and/or associativity:

     Conflict in state 8 between rule 2 and token '+' resolved as reduce.
     Conflict in state 8 between rule 2 and token '-' resolved as reduce.
     Conflict in state 8 between rule 2 and token '*' resolved as shift.
...

The next section lists states that still have conflicts.

     State 8 conflicts: 1 shift/reduce
     State 9 conflicts: 1 shift/reduce
     State 10 conflicts: 1 shift/reduce
     State 11 conflicts: 4 shift/reduce

The next section reports useless tokens, nonterminal and rules.  Useless
nonterminals and rules are removed in order to produce a smaller parser,
but useless tokens are preserved, since they might be used by the
scanner (note the difference between "useless" and "not used" below):

     Useless nonterminals:
        useless
     
     Terminals which are not used:
        STR
     
     Useless rules:
     #6     useless: STR;

The next section reproduces the exact grammar that Bison used:

     Grammar
     
       Number, Line, Rule
         0   5 $accept -> exp $end
         1   5 exp -> exp '+' exp
         2   6 exp -> exp '-' exp
         3   7 exp -> exp '*' exp
         4   8 exp -> exp '/' exp
         5   9 exp -> NUM

and reports the uses of the symbols:

     Terminals, with rules where they appear
     
     $end (0) 0
     '*' (42) 3
     '+' (43) 1
     '-' (45) 2
     '/' (47) 4
     error (256)
     NUM (258) 5
     
     Nonterminals, with rules where they appear
     
     $accept (8)
         on left: 0
     exp (9)
         on left: 1 2 3 4 5, on right: 0 1 2 3 4

Bison then proceeds onto the automaton itself, describing each state
with it set of "items", also known as "pointed rules".  Each item is a
production rule together with a point (marked by `.') that the input
cursor.

     state 0
     
         $accept  ->  . exp $   (rule 0)
     
         NUM         shift, and go to state 1
     
         exp         go to state 2

   This reads as follows: "state 0 corresponds to being at the very
beginning of the parsing, in the initial rule, right before the start
symbol (here, `exp').  When the parser returns to this state right
after having reduced a rule that produced an `exp', the control flow
jumps to state 2.  If there is no such transition on a nonterminal
symbol, and the lookahead is a `NUM', then this token is shifted on the
parse stack, and the control flow jumps to state 1.  Any other
lookahead triggers a syntax error."

   Even though the only active rule in state 0 seems to be rule 0, the
report lists `NUM' as a lookahead symbol because `NUM' can be at the
beginning of any rule deriving an `exp'.  By default Bison reports the
so-called "core" or "kernel" of the item set, but if you want to see
more detail you can invoke `bison' with `--report=itemset' to list all
the items, include those that can be derived:

     state 0
     
         $accept  ->  . exp $   (rule 0)
         exp  ->  . exp '+' exp   (rule 1)
         exp  ->  . exp '-' exp   (rule 2)
         exp  ->  . exp '*' exp   (rule 3)
         exp  ->  . exp '/' exp   (rule 4)
         exp  ->  . NUM   (rule 5)
     
         NUM         shift, and go to state 1
     
         exp         go to state 2

In the state 1...

     state 1
     
         exp  ->  NUM .   (rule 5)
     
         $default    reduce using rule 5 (exp)

the rule 5, `exp: NUM;', is completed.  Whatever the lookahead
(`$default'), the parser will reduce it.  If it was coming from state
0, then, after this reduction it will return to state 0, and will jump
to state 2 (`exp: go to state 2').

     state 2
     
         $accept  ->  exp . $   (rule 0)
         exp  ->  exp . '+' exp   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
     
         $           shift, and go to state 3
         '+'         shift, and go to state 4
         '-'         shift, and go to state 5
         '*'         shift, and go to state 6
         '/'         shift, and go to state 7

In state 2, the automaton can only shift a symbol.  For instance,
because of the item `exp -> exp . '+' exp', if the lookahead if `+', it
will be shifted on the parse stack, and the automaton control will jump
to state 4, corresponding to the item `exp -> exp '+' . exp'.  Since
there is no default action, any other token than those listed above
will trigger a syntax error.

   The state 3 is named the "final state", or the "accepting state":

     state 3
     
         $accept  ->  exp $ .   (rule 0)
     
         $default    accept

the initial rule is completed (the start symbol and the end of input
were read), the parsing exits successfully.

   The interpretation of states 4 to 7 is straightforward, and is left
to the reader.

     state 4
     
         exp  ->  exp '+' . exp   (rule 1)
     
         NUM         shift, and go to state 1
     
         exp         go to state 8
     
     state 5
     
         exp  ->  exp '-' . exp   (rule 2)
     
         NUM         shift, and go to state 1
     
         exp         go to state 9
     
     state 6
     
         exp  ->  exp '*' . exp   (rule 3)
     
         NUM         shift, and go to state 1
     
         exp         go to state 10
     
     state 7
     
         exp  ->  exp '/' . exp   (rule 4)
     
         NUM         shift, and go to state 1
     
         exp         go to state 11

   As was announced in beginning of the report, `State 8 conflicts: 1
shift/reduce':

     state 8
     
         exp  ->  exp . '+' exp   (rule 1)
         exp  ->  exp '+' exp .   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
     
         '*'         shift, and go to state 6
         '/'         shift, and go to state 7
     
         '/'         [reduce using rule 1 (exp)]
         $default    reduce using rule 1 (exp)

   Indeed, there are two actions associated to the lookahead `/':
either shifting (and going to state 7), or reducing rule 1.  The
conflict means that either the grammar is ambiguous, or the parser lacks
information to make the right decision.  Indeed the grammar is
ambiguous, as, since we did not specify the precedence of `/', the
sentence `NUM + NUM / NUM' can be parsed as `NUM + (NUM / NUM)', which
corresponds to shifting `/', or as `(NUM + NUM) / NUM', which
corresponds to reducing rule 1.

   Because in LALR(1) parsing a single decision can be made, Bison
arbitrarily chose to disable the reduction, see *Note Shift/Reduce
Conflicts: Shift/Reduce.  Discarded actions are reported in between
square brackets.

   Note that all the previous states had a single possible action:
either shifting the next token and going to the corresponding state, or
reducing a single rule.  In the other cases, i.e., when shifting _and_
reducing is possible or when _several_ reductions are possible, the
lookahead is required to select the action.  State 8 is one such state:
if the lookahead is `*' or `/' then the action is shifting, otherwise
the action is reducing rule 1.  In other words, the first two items,
corresponding to rule 1, are not eligible when the lookahead is `*',
since we specified that `*' has higher precedence that `+'.  More
generally, some items are eligible only with some set of possible
lookaheads.  When run with `--report=lookahead', Bison specifies these
lookaheads:

     state 8
     
         exp  ->  exp . '+' exp  [$, '+', '-', '/']   (rule 1)
         exp  ->  exp '+' exp .  [$, '+', '-', '/']   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
     
         '*'         shift, and go to state 6
         '/'         shift, and go to state 7
     
         '/'         [reduce using rule 1 (exp)]
         $default    reduce using rule 1 (exp)

   The remaining states are similar:

     state 9
     
         exp  ->  exp . '+' exp   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp '-' exp .   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
     
         '*'         shift, and go to state 6
         '/'         shift, and go to state 7
     
         '/'         [reduce using rule 2 (exp)]
         $default    reduce using rule 2 (exp)
     
     state 10
     
         exp  ->  exp . '+' exp   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp '*' exp .   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
     
         '/'         shift, and go to state 7
     
         '/'         [reduce using rule 3 (exp)]
         $default    reduce using rule 3 (exp)
     
     state 11
     
         exp  ->  exp . '+' exp   (rule 1)
         exp  ->  exp . '-' exp   (rule 2)
         exp  ->  exp . '*' exp   (rule 3)
         exp  ->  exp . '/' exp   (rule 4)
         exp  ->  exp '/' exp .   (rule 4)
     
         '+'         shift, and go to state 4
         '-'         shift, and go to state 5
         '*'         shift, and go to state 6
         '/'         shift, and go to state 7
     
         '+'         [reduce using rule 4 (exp)]
         '-'         [reduce using rule 4 (exp)]
         '*'         [reduce using rule 4 (exp)]
         '/'         [reduce using rule 4 (exp)]
         $default    reduce using rule 4 (exp)

Observe that state 11 contains conflicts due to the lack of precedence
of `/' wrt `+', `-', and `*', but also because the associativity of `/'
is not specified.


File: bison.info,  Node: Tracing,  Prev: Understanding,  Up: Debugging

Tracing Your Parser
===================

   If a Bison grammar compiles properly but doesn't do what you want
when it runs, the `yydebug' parser-trace feature can help you figure
out why.

   There are several means to enable compilation of trace facilities:

the macro `YYDEBUG'
     Define the macro `YYDEBUG' to a nonzero value when you compile the
     parser.  This is compliant with POSIX Yacc.  You could use
     `-DYYDEBUG=1' as a compiler option or you could put `#define
     YYDEBUG 1' in the prologue of the grammar file (*note The
     Prologue: Prologue.).

the option `-t', `--debug'
     Use the `-t' option when you run Bison (*note Invoking Bison:
     Invocation.).  This is POSIX compliant too.

the directive `%debug'
     Add the `%debug' directive (*note Bison Declaration Summary: Decl
     Summary.).  This is a Bison extension, which will prove useful
     when Bison will output parsers for languages that don't use a
     preprocessor.  Unless POSIX and Yacc portability matter to you,
     this is the preferred solution.

   We suggest that you always enable the debug option so that debugging
is always possible.

   The trace facility outputs messages with macro calls of the form
`YYFPRINTF (stderr, FORMAT, ARGS)' where FORMAT and ARGS are the usual
`printf' format and arguments.  If you define `YYDEBUG' to a nonzero
value but do not define `YYFPRINTF', `<stdio.h>' is automatically
included and `YYPRINTF' is defined to `fprintf'.

   Once you have compiled the program with trace facilities, the way to
request a trace is to store a nonzero value in the variable `yydebug'.
You can do this by making the C code do it (in `main', perhaps), or you
can alter the value with a C debugger.

   Each step taken by the parser when `yydebug' is nonzero produces a
line or two of trace information, written on `stderr'.  The trace
messages tell you these things:

   * Each time the parser calls `yylex', what kind of token was read.

   * Each time a token is shifted, the depth and complete contents of
     the state stack (*note Parser States::).

   * Each time a rule is reduced, which rule it is, and the complete
     contents of the state stack afterward.

   To make sense of this information, it helps to refer to the listing
file produced by the Bison `-v' option (*note Invoking Bison:
Invocation.).  This file shows the meaning of each state in terms of
positions in various rules, and also what each state will do with each
possible input token.  As you read the successive trace messages, you
can see that the parser is functioning according to its specification in
the listing file.  Eventually you will arrive at the place where
something undesirable happens, and you will see which parts of the
grammar are to blame.

   The parser file is a C program and you can use C debuggers on it,
but it's not easy to interpret what it is doing.  The parser function
is a finite-state machine interpreter, and aside from the actions it
executes the same code over and over.  Only the values of variables
show where in the grammar it is working.

   The debugging information normally gives the token type of each token
read, but not its semantic value.  You can optionally define a macro
named `YYPRINT' to provide a way to print the value.  If you define
`YYPRINT', it should take three arguments.  The parser will pass a
standard I/O stream, the numeric code for the token type, and the token
value (from `yylval').

   Here is an example of `YYPRINT' suitable for the multi-function
calculator (*note Declarations for `mfcalc': Mfcalc Decl.):

     %{
       static void print_token_value (FILE *, int, YYSTYPE);
       #define YYPRINT(file, type, value) print_token_value (file, type, value)
     %}
     
     ... %% ... %% ...
     
     static void
     print_token_value (FILE *file, int type, YYSTYPE value)
     {
       if (type == VAR)
         fprintf (file, "%s", value.tptr->name);
       else if (type == NUM)
         fprintf (file, "%d", value.val);
     }


File: bison.info,  Node: Invocation,  Next: Table of Symbols,  Prev: Debugging,  Up: Top

Invoking Bison
**************

   The usual way to invoke Bison is as follows:

     bison INFILE

   Here INFILE is the grammar file name, which usually ends in `.y'.
The parser file's name is made by replacing the `.y' with `.tab.c'.
Thus, the `bison foo.y' filename yields `foo.tab.c', and the `bison
hack/foo.y' filename yields `hack/foo.tab.c'.  It's also possible, in
case you are writing C++ code instead of C in your grammar file, to
name it `foo.ypp' or `foo.y++'.  Then, the output files will take an
extension like the given one as input (respectively `foo.tab.cpp' and
`foo.tab.c++').  This feature takes effect with all options that
manipulate filenames like `-o' or `-d'.

   For example :

     bison -d INFILE.YXX

will produce `infile.tab.cxx' and `infile.tab.hxx', and

     bison -d -o OUTPUT.C++ INFILE.Y

will produce `output.c++' and `outfile.h++'.

   For compatibility with POSIX, the standard Bison distribution also
contains a shell script called `yacc' that invokes Bison with the `-y'
option.

* Menu:

* Bison Options::     All the options described in detail,
                        in alphabetical order by short options.
* Option Cross Key::  Alphabetical list of long options.
* Yacc Library::      Yacc-compatible `yylex' and `main'.


File: bison.info,  Node: Bison Options,  Next: Option Cross Key,  Up: Invocation

Bison Options
=============

   Bison supports both traditional single-letter options and mnemonic
long option names.  Long option names are indicated with `--' instead of
`-'.  Abbreviations for option names are allowed as long as they are
unique.  When a long option takes an argument, like `--file-prefix',
connect the option name and the argument with `='.

   Here is a list of options that can be used with Bison, alphabetized
by short option.  It is followed by a cross key alphabetized by long
option.

Operations modes:
`-h'
`--help'
     Print a summary of the command-line options to Bison and exit.

`-V'
`--version'
     Print the version number of Bison and exit.

`-y'
`--yacc'
     Equivalent to `-o y.tab.c'; the parser output file is called
     `y.tab.c', and the other outputs are called `y.output' and
     `y.tab.h'.  The purpose of this option is to imitate Yacc's output
     file name conventions.  Thus, the following shell script can
     substitute for Yacc, and the Bison distribution contains such a
     script for compatibility with POSIX:

          #! /bin/sh
          bison -y "$
          "

Tuning the parser:

`-S FILE'
`--skeleton=FILE'
     Specify the skeleton to use.  You probably don't need this option
     unless you are developing Bison.

`-t'
`--debug'
     In the parser file, define the macro `YYDEBUG' to 1 if it is not
     already defined, so that the debugging facilities are compiled.
     *Note Tracing Your Parser: Tracing.

`--locations'
     Pretend that `%locations' was specified.  *Note Decl Summary::.

`-p PREFIX'
`--name-prefix=PREFIX'
     Pretend that `%name-prefix="PREFIX"' was specified.  *Note Decl
     Summary::.

`-l'
`--no-lines'
     Don't put any `#line' preprocessor commands in the parser file.
     Ordinarily Bison puts them in the parser file so that the C
     compiler and debuggers will associate errors with your source
     file, the grammar file.  This option causes them to associate
     errors with the parser file, treating it as an independent source
     file in its own right.

`-n'
`--no-parser'
     Pretend that `%no-parser' was specified.  *Note Decl Summary::.

`-k'
`--token-table'
     Pretend that `%token-table' was specified.  *Note Decl Summary::.

Adjust the output:

`-d'
`--defines'
     Pretend that `%defines' was specified, i.e., write an extra output
     file containing macro definitions for the token type names defined
     in the grammar and the semantic value type `YYSTYPE', as well as a
     few `extern' variable declarations.  *Note Decl Summary::.

`--defines=DEFINES-FILE'
     Same as above, but save in the file DEFINES-FILE.

`-b FILE-PREFIX'
`--file-prefix=PREFIX'
     Pretend that `%verbose' was specified, i.e, specify prefix to use
     for all Bison output file names.  *Note Decl Summary::.

`-r THINGS'
`--report=THINGS'
     Write an extra output file containing verbose description of the
     comma separated list of THINGS among:

    `state'
          Description of the grammar, conflicts (resolved and
          unresolved), and LALR automaton.

    `lookahead'
          Implies `state' and augments the description of the automaton
          with each rule's lookahead set.

    `itemset'
          Implies `state' and augments the description of the automaton
          with the full set of items for each state, instead of its
          core only.

     For instance, on the following grammar

`-v'
`--verbose'
     Pretend that `%verbose' was specified, i.e, write an extra output
     file containing verbose descriptions of the grammar and parser.
     *Note Decl Summary::.

`-o FILENAME'
`--output=FILENAME'
     Specify the FILENAME for the parser file.

     The other output files' names are constructed from FILENAME as
     described under the `-v' and `-d' options.

`-g'
     Output a VCG definition of the LALR(1) grammar automaton computed
     by Bison.  If the grammar file is `foo.y', the VCG output file will
     be `foo.vcg'.

`--graph=GRAPH-FILE'
     The behavior of -GRAPH is the same than `-g'.  The only difference
     is that it has an optional argument which is the name of the
     output graph filename.


File: bison.info,  Node: Option Cross Key,  Next: Yacc Library,  Prev: Bison Options,  Up: Invocation

Option Cross Key
================

   Here is a list of options, alphabetized by long option, to help you
find the corresponding short option.

     --debug                               -t
     --defines=DEFINES-FILE          -d
     --file-prefix=PREFIX                  -b FILE-PREFIX
     --graph=GRAPH-FILE              -d
     --help                                -h
     --name-prefix=PREFIX                  -p NAME-PREFIX
     --no-lines                            -l
     --no-parser                           -n
     --output=OUTFILE                      -o OUTFILE
     --token-table                         -k
     --verbose                             -v
     --version                             -V
     --yacc                                -y


File: bison.info,  Node: Yacc Library,  Prev: Option Cross Key,  Up: Invocation

Yacc Library
============

   The Yacc library contains default implementations of the `yyerror'
and `main' functions.  These default implementations are normally not
useful, but POSIX requires them.  To use the Yacc library, link your
program with the `-ly' option.  Note that Bison's implementation of the
Yacc library is distributed under the terms of the GNU General Public
License (*note Copying::).

   If you use the Yacc library's `yyerror' function, you should declare
`yyerror' as follows:

     int yyerror (char const *);

   Bison ignores the `int' value returned by this `yyerror'.  If you
use the Yacc library's `main' function, your `yyparse' function should
have the following type signature:

     int yyparse (void);


File: bison.info,  Node: FAQ,  Next: Copying This Manual,  Prev: Glossary,  Up: Top

Frequently Asked Questions
**************************

   Several questions about Bison come up occasionally.  Here some of
them are addressed.

* Menu:

* Parser Stack Overflow::      Breaking the Stack Limits


File: bison.info,  Node: Parser Stack Overflow,  Up: FAQ

Parser Stack Overflow
=====================

     My parser returns with error with a `parser stack overflow'
     message.  What can I do?

   This question is already addressed elsewhere, *Note Recursive Rules:
Recursion.

